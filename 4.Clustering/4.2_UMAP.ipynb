{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"metadata":{},"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# Configuration for suppressing warnings\n","import warnings\n","warnings.filterwarnings('ignore', category=DeprecationWarning)  # Suppress specific categories as needed\n","\n","# Importing standard libraries and configuring path\n","import sys\n","sys.path.append('..')\n","sys.path.append('../utils/')\n","\n","# Importing third-party libraries for data manipulation, machine learning, and visualization\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import hiplot as hip\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import BoundaryNorm\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler, scale\n","from sklearn.cluster import KMeans\n","from sklearn.mixture import GaussianMixture\n","from tqdm import tqdm\n","from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score, silhouette_score\n","from sklearn.datasets import make_blobs\n","import umap\n","\n","# Importing Plotly for interactive plotting\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","\n","# Importing local utilities/modules, assuming these are located in the 'utils' directory\n","from utils.EDA import *\n","from utils.Clustering import *\n","\n","# IPython specific configuration to set the backend for rendering high-resolution images in Jupyter notebooks\n","%config InlineBackend.figure_formats = ['retina']"]},{"cell_type":"code","execution_count":null,"metadata":{"metadata":{}},"outputs":[],"source":["plt.style.use('default')\n","\n","plt.rcParams.update({\n","    'font.size': 20,\n","    'axes.linewidth': 2,\n","    'axes.titlesize': 20,\n","    'axes.edgecolor': 'black',\n","    'axes.labelsize': 18,\n","    'axes.grid': True,\n","    'lines.linewidth': 1.5,\n","    'lines.markersize': 6,\n","    'figure.figsize': (20, 8),\n","    'xtick.labelsize': 16,\n","    'ytick.labelsize': 16,\n","    'font.family': 'Times New Roman',\n","    'legend.fontsize': 13,\n","    'legend.framealpha': 0.8,\n","    'legend.edgecolor': 'black',\n","    'legend.shadow': False,\n","    'legend.fancybox': True,\n","    'legend.frameon': True,\n","})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["path_to_dataset = \"../3.Feature_Engineering/Datasets/OP6_Features.parquet\"\n","df = pd.read_parquet(path_to_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df1 = df[df['Machine']=='M01']\n","df1.reset_index(drop=True,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["features = ['Z_D3', 'Z_D2', 'Y_D3', 'Y_D2', 'X_D3', 'X_Rolling Energy Entropy','Y_Rolling Energy Entropy','Z_Rolling Energy Entropy', 'Y_Rolling RMS']\n","\n","plot_scatter_matrix_FE(df, machine='M01', process='OP06', cols=features, sample_frac=0.1, random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["- https://ravindranathsawane.medium.com/spectral-clustering-algorithm-b469938a8841\n","- https://github.com/koaning/drawdata?tab=readme-ov-file"]},{"cell_type":"markdown","metadata":{},"source":["# U-MAP"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = df1[features]\n","\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X.iloc[::100])\n","target = df1['Label'].iloc[::100].values  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["reducer = umap.UMAP(random_state=42)\n","X_umap = reducer.fit_transform(X_scaled)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["embedding = reducer.embedding_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, ax = plt.subplots(1, figsize=(8, 6))\n","\n","boundaries = [0, 0.5, 1]\n","norm = BoundaryNorm(boundaries, ncolors=256, clip=True)\n","\n","\n","scatter = ax.scatter(*embedding.T, s=0.1, c=target, cmap='Spectral', norm=norm, alpha=1.0)\n","\n","\n","cbar = plt.colorbar(scatter, ax=ax, ticks=[0, 1])\n","cbar.set_label('Target')\n","\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["neighbor_values = [5, 10, 15, 20, 30]  # List of different number of neighbors to try\n","\n","fig, axs = plt.subplots(len(neighbor_values), 1, figsize=(8, 6 * len(neighbor_values)))\n","\n","boundaries = [0, 0.5, 1]\n","norm = BoundaryNorm(boundaries, ncolors=256, clip=True)\n","\n","for i, n_neighbors in enumerate(neighbor_values):\n","    reducer = umap.UMAP(n_neighbors=n_neighbors, random_state=42, n_jobs=1)\n","    X_umap = reducer.fit_transform(X_scaled)\n","    embedding = reducer.embedding_\n","    \n","    ax = axs[i] if len(neighbor_values) > 1 else axs\n","    scatter = ax.scatter(*embedding.T, s=0.1, c=target, cmap='Spectral', norm=norm, alpha=1.0)\n","    ax.set_title(f'UMAP with n_neighbors = {n_neighbors}')\n","\n","    if i == len(neighbor_values) - 1:\n","        cbar = plt.colorbar(scatter, ax=ax, ticks=[0, 1])\n","        cbar.set_label('Target')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def fit_gmm_evaluate(data, n_components_range, random_state=0, covariance_type='diag'):\n","    \"\"\"\n","    Fit Gaussian Mixture Models for a range of component numbers and evaluate using several metrics.\n","    \n","    Parameters:\n","        data (np.ndarray): Data to fit the models on.\n","        n_components_range (range): Range of component numbers to fit the models for.\n","        random_state (int): Random state for reproducibility of the models.\n","        \n","    Returns:\n","        dict: Dictionary containing fitted models and evaluation metrics.\n","    \"\"\"\n","    # Storage for models and metrics\n","    models = []\n","    bics = []\n","    log_likelihoods = []\n","    davies_bouldin_indices = []\n","    calinski_harabasz_indices = []\n","\n","    # Fit models and compute metrics\n","    for n in tqdm(n_components_range, desc='Fitting Models'):\n","        gmm = GaussianMixture(n_components=n, covariance_type=covariance_type, random_state=random_state).fit(data)\n","        models.append(gmm)\n","        bics.append(gmm.bic(data))\n","        log_likelihoods.append(gmm.score(data) * len(data))  # Adjusted log likelihood\n","\n","        # Predict the labels\n","        labels = gmm.predict(data)\n","\n","        # Calculate metrics if there is more than one cluster\n","        if n > 1:\n","            davies_bouldin_indices.append(davies_bouldin_score(data, labels))\n","            calinski_harabasz_indices.append(calinski_harabasz_score(data, labels))\n","        else:\n","            davies_bouldin_indices.append(None)\n","            calinski_harabasz_indices.append(None)\n","\n","    return {\n","        \"models\": models,\n","        \"bics\": bics,\n","        \"log_likelihoods\": log_likelihoods,\n","        \"davies_bouldin_indices\": davies_bouldin_indices,\n","        \"calinski_harabasz_indices\": calinski_harabasz_indices\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the range of neighbors to evaluate\n","neighbor_values = [5, 10, 15, 20, 30]\n","\n","# Storage for evaluation metrics\n","all_gmm_metrics = {}\n","\n","for n_neighbors in neighbor_values:\n","    reducer = umap.UMAP(n_neighbors=n_neighbors, random_state=42, n_jobs=1)\n","    X_umap = reducer.fit_transform(X_scaled)\n","    \n","    # Fit GMM and evaluate\n","    gmm_metrics = fit_gmm_evaluate(X_umap, range(2, 11), random_state=42)\n","    \n","    all_gmm_metrics[n_neighbors] = gmm_metrics\n","\n","# Plot the GMM evaluation metrics for each embedding\n","fig, axs = plt.subplots(4, 1, figsize=(10, 24))\n","\n","for n_neighbors in neighbor_values:\n","    metrics = all_gmm_metrics[n_neighbors]\n","    n_components = range(2, 11)\n","    \n","    # Plot BIC\n","    axs[0].plot(n_components, metrics[\"bics\"], label=f'n_neighbors = {n_neighbors}')\n","    axs[0].set_title('BIC Scores for Different UMAP Embeddings')\n","    axs[0].set_xlabel('Number of Components')\n","    axs[0].set_ylabel('BIC')\n","    \n","    # Plot log likelihood\n","    axs[1].plot(n_components, metrics[\"log_likelihoods\"], label=f'n_neighbors = {n_neighbors}')\n","    axs[1].set_title('Log Likelihood Scores for Different UMAP Embeddings')\n","    axs[1].set_xlabel('Number of Components')\n","    axs[1].set_ylabel('Log Likelihood')\n","    \n","    # Plot Davies-Bouldin index\n","    axs[2].plot(n_components, metrics[\"davies_bouldin_indices\"], label=f'n_neighbors = {n_neighbors}')\n","    axs[2].set_title('Davies-Bouldin Index for Different UMAP Embeddings')\n","    axs[2].set_xlabel('Number of Components')\n","    axs[2].set_ylabel('Davies-Bouldin Index')\n","    \n","    # Plot Calinski-Harabasz index\n","    axs[3].plot(n_components, metrics[\"calinski_harabasz_indices\"], label=f'n_neighbors = {n_neighbors}')\n","    axs[3].set_title('Calinski-Harabasz Index for Different UMAP Embeddings')\n","    axs[3].set_xlabel('Number of Components')\n","    axs[3].set_ylabel('Calinski-Harabasz Index')\n","\n","# Add legends\n","for ax in axs:\n","    ax.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = df1[features]\n","\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","target = df1['Label'].values  "]},{"cell_type":"markdown","metadata":{},"source":["# UMAP in batches"]},{"cell_type":"markdown","metadata":{},"source":["I've tried to fit in this way because the dataset is too big"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Fit UMAP on a subset of the data\n","subset_size = 10000  # Adjust based on memory constraints\n","umap_model = umap.UMAP(n_neighbors=15, random_state=42, n_jobs=1)\n","umap_model.fit(X_scaled[::100])\n","\n","# Function to transform data in batches\n","def transform_in_batches(umap_model, data, batch_size=10000):\n","    embeddings = []\n","    for i in tqdm(range(0, len(data), batch_size), desc='Transforming batches'):\n","        batch = data[i:i+batch_size]\n","        embedding = umap_model.transform(batch)\n","        embeddings.append(embedding)\n","    return np.vstack(embeddings)\n","\n","# Transform the entire dataset in batches\n","X_umap = transform_in_batches(umap_model, X_scaled)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_umap"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create UMAP embedding with 15 neighbors\n","#n_neighbors = 15\n","#reducer = umap.UMAP(n_neighbors=n_neighbors, random_state=42, n_jobs=1)\n","#X_umap = reducer.fit_transform(X_scaled)\n","\n","# Fit GMM with 3 components\n","n_components = 3\n","gmm = GaussianMixture(n_components=n_components, covariance_type='full', random_state=42)\n","gmm.fit(X_umap)\n","labels = gmm.predict(X_umap)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a DataFrame with the embedding and labels\n","df_umap = pd.DataFrame(X_umap, columns=['UMAP1', 'UMAP2'])\n","df_umap['Cluster'] = labels\n","\n","df_umap['Cluster'] = df_umap['Cluster'].astype('str')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Visualize with Plotly\n","fig = px.scatter(df_umap, x='UMAP1', y='UMAP2', color='Cluster', title='UMAP Embedding with GMM Clustering (3 Components)',\n","                 color_continuous_scale='Viridis')\n","fig.update_layout(coloraxis_colorbar=dict(title='Cluster'))\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Visualize with Plotly\n","fig = px.scatter(df_umap, x='UMAP1', y='UMAP2', color='Cluster', title='UMAP Embedding with GMM Clustering (3 Components)',\n","                 color_continuous_scale='Viridis')\n","fig.update_layout(coloraxis_colorbar=dict(title='Cluster'))\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df1.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_original = df1[features]\n","df_original['Unique_Code'] = df1['Unique_Code']\n","df_original['Label'] = df1['Label']\n","df_original = df_original[::100]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_original.reset_index(drop=True,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_original['Cluster'] = df_umap['Cluster']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_original.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_original"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_vars2 = ['Z_D3', 'Z_D2', 'Y_D3', 'Y_D2', 'X_D3', 'X_Rolling Energy Entropy',\n","       'Y_Rolling Energy Entropy', 'Z_Rolling Energy Entropy', 'Y_Rolling RMS',\n","       'Unique_Code', 'Cluster','Label']\n","visualize_with_hiplot(df_original[plot_vars2].sample(frac=0.01,random_state=0))"]},{"cell_type":"markdown","metadata":{},"source":["# Spectral Clustering"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#https://towardsdatascience.com/spectral-clustering-aba2640c0d5b"]}],"metadata":{"kernelspec":{"display_name":"ETL","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":4}

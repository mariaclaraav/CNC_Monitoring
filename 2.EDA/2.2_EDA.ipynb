{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../utils/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import numpy as np\n",
    "import hiplot as hip \n",
    "#import polars as pl\n",
    "from scipy.signal import welch,  butter, filtfilt\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from plotly.subplots import make_subplots\n",
    "from utils.EDA import*\n",
    "#import endaq.plot.dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 20,\n",
    "    'axes.linewidth': 2,\n",
    "    'axes.titlesize': 20,\n",
    "    'axes.edgecolor': 'black',\n",
    "    'axes.labelsize': 18,\n",
    "    'axes.grid': True,\n",
    "    'lines.linewidth': 1.5,\n",
    "    'lines.markersize': 6,\n",
    "    'figure.figsize': (20, 8),\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "    'font.family': 'Times New Roman',\n",
    "    'legend.fontsize': 13,\n",
    "    'legend.framealpha': 0.8,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.shadow': False,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.frameon': True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_to_dataset = \"../1.ETL/Datasets/Processed/ETL2_train_label.parquet\"\n",
    "df = pd.read_parquet(path_to_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[(df['Process']=='OP06')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df1 = df2[(df2['Machine']=='M01') & (df2['Process']=='OP06')]\n",
    "df1['Unique_Code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df1['Unique_Code'].unique()[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for rows where the 'Label' column equals 1\n",
    "df_filtered = df[df['Label'] == 1]\n",
    "\n",
    "# Group by 'Machine' and 'Process', and extract the Unique_Code for each combination\n",
    "unique_codes_per_machine_process = {}\n",
    "for (machine, process), group in df_filtered.groupby(['Machine', 'Process']):\n",
    "    unique_codes = group['Unique_Code'].unique()\n",
    "    if machine not in unique_codes_per_machine_process:\n",
    "        unique_codes_per_machine_process[machine] = {}\n",
    "    unique_codes_per_machine_process[machine][process] = unique_codes\n",
    "\n",
    "# Print the Unique Codes associated with Label 1 for each machine and process combination\n",
    "for machine, processes in unique_codes_per_machine_process.items():\n",
    "    print(f\"Machine {machine}:\\n\")\n",
    "    for process, codes in processes.items():\n",
    "        print(f\"  Process {process} with anomaly: {codes}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df1 = df[(df['Machine']=='M01') & (df['Process']=='OP06')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_df = pd.read_parquet('../1.ETL/Datasets/Processed/ETL2_train_label.parquet')\n",
    "#label_df[(label_df['Label']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = label_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data acquisition is done indirectly using Bosch CISS accelerometer sensors mounted at the spindle housing's rear end;\n",
    "- The sensors maintain a constant distance to the tool center point, and their axes align with the machine's linear motion axi;\n",
    "- The frequencies of the tool operations are in a range of 75 Hz to 1 kHz;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The machine performs a sequence of several operations using different tools on aluminium parts to work the specified design;\n",
    "- The machines produce different parts and the process flow changes over time. To study the drift between machines and over time, the dataset is built with 15 different tool operations that run on all 3 machines at different time frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Table gives an overview on the characteristics of the different operations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_code_index_matplotlib(df, process='OP06', machine = 'M01', axis='Z_axis', decimation_factor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_code_index_matplotlib(df1, process='OP06', machine = 'M01',axis='Y_axis', decimation_factor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "plot_by_code_index_matplotlib(df1, process='OP06', machine = 'M01',axis='X_axis', decimation_factor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_axis_matplotlib(df, process='OP06', machine='M01', by_code=False,decimation_factor=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data frequency for diffent process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a FFT\n",
    "def calculate_fft(df, column_name, unique_code):\n",
    "    # Filtrando os dados por 'Unique_Code'\n",
    "    data_filtered = df[df['Unique_Code'] == unique_code]\n",
    "    freq = 2000\n",
    "    \n",
    "    fft_values = np.fft.fft(data_filtered[column_name])\n",
    "    n = len(fft_values)\n",
    "    frequencies = np.fft.fftfreq(n, d=1/freq)\n",
    "    magnitudes = np.abs(fft_values)[:n // 2][1:]  # removendo a componente dc do sinal\n",
    "    return frequencies[:n // 2][1:], magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['Unique_Code']=='M01_OP06_Aug_2021_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "#Unique Codes \n",
    "unique_codes = ['M01_OP06_Aug_2019_1','M01_OP06_Aug_2019_3','M01_OP06_Aug_2021_2','M01_OP06_Aug_2021_4', 'M02_OP06_Aug_2019_1', 'M03_OP06_Aug_2019_1']\n",
    "\n",
    "for code in unique_codes:\n",
    "    frequencies, magnitudes = calculate_fft(df2, 'Y_axis', code)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=frequencies, y=magnitudes, mode='lines', name=code))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='FFT - Y_axis',\n",
    "    xaxis_title='Frequency (Hz)',\n",
    "    yaxis_title='Magnitude',\n",
    "    autosize=False,    \n",
    "    width=1200)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't seem like there are significant differences between operations that might indicate the presence of an anomaly operation, but there does appear to be a change in the natural frequency between the machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Loop over each Unique_Code to add histograms to the same plot\n",
    "for code in df1['Unique_Code'].unique():\n",
    "    # Filter data by Unique_Code and take a sample of it\n",
    "    sample_data = df1[df1['Unique_Code'] == code].sample(frac=0.3, random_state=42)\n",
    "\n",
    "    # Add histogram to the chart\n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=sample_data['X_axis'],\n",
    "        name=f'{code}',  \n",
    "        opacity=0.75,  # Adjust opacity for better visualization of overlaps\n",
    "        histnorm='probability'  # Normalize histogram to show proportions\n",
    "    ))\n",
    "\n",
    "# Update layout for better visualization and comparison\n",
    "fig.update_layout(\n",
    "    title_text='X_axis distribution - M01 OP06', \n",
    "    xaxis_title_text='X_axis',\n",
    "    yaxis_title_text='Count', \n",
    "    bargap=0.1, \n",
    "    barmode='overlay')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Loop over each Unique_Code to add histograms to the same plot\n",
    "for code in df1['Unique_Code'].unique():\n",
    "    # Filter data by Unique_Code and take a sample of it\n",
    "    sample_data = df1[df1['Unique_Code'] == code].sample(frac=0.3, random_state=42)\n",
    "\n",
    "    # Add histogram to the chart\n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=sample_data['Y_axis'],\n",
    "        name=f'{code}',  \n",
    "        opacity=0.75,  # Adjust opacity for better visualization of overlaps\n",
    "        histnorm='probability'  # Normalize histogram to show proportions\n",
    "    ))\n",
    "\n",
    "# Update layout for better visualization and comparison\n",
    "fig.update_layout(\n",
    "    title_text='Y_axis distribution - M01 OP06', \n",
    "    xaxis_title_text='Y_axis', \n",
    "    yaxis_title_text='Count', \n",
    "    bargap=0.1,\n",
    "    barmode='overlay')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Loop over each Unique_Code to add histograms to the same plot\n",
    "for code in df1['Unique_Code'].unique():\n",
    "    # Filter data by Unique_Code and take a sample of it\n",
    "    sample_data = df1[df1['Unique_Code'] == code].sample(frac=0.3, random_state=42)\n",
    "\n",
    "    # Add histogram to the chart\n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=sample_data['Z_axis'],\n",
    "        name=f'{code}',  \n",
    "        opacity=0.75,  # Adjust opacity for better visualization of overlaps\n",
    "        histnorm='probability'  # Normalize histogram to show proportions\n",
    "    ))\n",
    "\n",
    "# Update layout for better visualization and comparison\n",
    "fig.update_layout(\n",
    "    title_text='Z_axis distribution - M01 OP06', \n",
    "    xaxis_title_text='Z_axis', \n",
    "    yaxis_title_text='Count', \n",
    "    bargap=0.1,\n",
    "    barmode='overlay')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 2000  # Sampling rate in Hz\n",
    "\n",
    "# Desired columns\n",
    "columns = ['X_axis', 'Y_axis', 'Z_axis']\n",
    "\n",
    "code = df1['Unique_Code'].unique()[0]\n",
    "selected_df = df1[(df1['Unique_Code'] == code)]\n",
    "\n",
    "# Number of rows and columns for the subplots\n",
    "num_rows = 3\n",
    "num_columns = 1\n",
    "\n",
    "# Creating the subplots\n",
    "plt.figure(figsize=(10, 8))  # Adjust the figure size as needed\n",
    "\n",
    "for i, column in enumerate(selected_df[columns].columns):\n",
    "    plt.subplot(num_rows, num_columns, i + 1)\n",
    "    \n",
    "    # Calculate the FFT using the Welch method with the specified sampling rate\n",
    "    f, Pxx = welch(selected_df[column], fs=fs)\n",
    "    \n",
    "    plt.plot(f, np.sqrt(Pxx), label=column)\n",
    "    plt.xlabel('Frequency [Hz]', fontsize=18)\n",
    "    plt.ylabel(f'{column}', fontsize=18)\n",
    "    plt.title(f'FFT of {column}', fontsize=20)\n",
    "    plt.tick_params(axis='x', which='major', labelsize=16)\n",
    "    plt.tick_params(axis='y', which='major', labelsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, this signal cannot be filtered because it contains important components at higher frequencies—it's not just noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nahlkdlkanl,ndlçnlçkdsnjçlk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 2000  # Sample frequency (Hz)\n",
    "cutoff = 500  # Cut-off frequency\n",
    "order = 4  # Filter order\n",
    "\n",
    "def filter_data(df, colunas, fs, cutoff_frequency, order):\n",
    "    \"\"\"\n",
    "    Aplica um filtro Butterworth passa-baixo às colunas especificadas, separadamente para cada viagem, \n",
    "    e adiciona os dados filtrados ao DataFrame original como novas colunas.\n",
    "\n",
    "    Args:\n",
    "    - df: DataFrame original.\n",
    "    - colunas: Lista de colunas a serem filtradas.\n",
    "    - fs: Taxa de amostragem em Hz.\n",
    "    - cutoff_frequency: Frequência de corte em Hz.\n",
    "    \"\"\"\n",
    "    # Projetar o filtro Butterworth passa-baixo\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff_frequency / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "\n",
    "    # Iterar sobre cada viagem\n",
    "    for code in df['Unique_Code'].unique():\n",
    "        # Selecionar dados da viagem atual\n",
    "        code_indices = df['Unique_Code'] == code\n",
    "\n",
    "        # Filtrar cada coluna selecionada para a viagem atual\n",
    "        for coluna in colunas:\n",
    "            coluna_filtrada = f'{coluna}_filt'\n",
    "            df.loc[code_indices, coluna_filtrada] = filtfilt(b, a, df.loc[code_indices, coluna])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_para_filtrar = ['X_axis','Y_axis','Z_axis']\n",
    "filter_data(df1, colunas_para_filtrar, fs = 2000, cutoff_frequency = 500, order = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filtered_data(df, code, colunas):\n",
    "    \"\"\"\n",
    "    Plota a comparação entre dados originais e filtrados para uma viagem e intervalo de Km específicos.\n",
    "\n",
    "    Args:\n",
    "    - df: DataFrame contendo dados originais e filtrados.\n",
    "    - trip: Nome da viagem (ex: 'Trip 1').\n",
    "    - colunas: Lista de colunas a serem plotadas.\n",
    "    - km_inicial: Início do intervalo de quilometragem para plotar.\n",
    "    - km_final: Fim do intervalo de quilometragem para plotar.\n",
    "    \"\"\"\n",
    "    code = df['Unique_Code'].unique()[code]\n",
    "    # Filtrar o DataFrame pela viagem e intervalo de Km\n",
    "    df_filtered = df[(df['Unique_Code'] == code)]\n",
    "\n",
    "    # Plotando os dados\n",
    "    for coluna in colunas:\n",
    "        plt.figure(figsize=(18, 6))\n",
    "        plt.plot(df_filtered['Time'], df_filtered[coluna], label=f'Original {coluna}', color='blue')\n",
    "        plt.plot(df_filtered['Time'], df_filtered[f'{coluna}_filt'], label=f'Filtrado {coluna}', color='red')\n",
    "        plt.title(f'Compare Original x Filtered - {coluna} - {code}')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel(coluna)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_para_plotar = ['X_axis','Y_axis','Z_axis']\n",
    "plot_filtered_data(df1, 16, colunas_para_plotar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_para_plotar = ['X_axis','Y_axis','Z_axis']\n",
    "plot_filtered_data(df1, 0, colunas_para_plotar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_para_plotar = ['X_axis','Y_axis','Z_axis']\n",
    "plot_filtered_data(df1, 18, colunas_para_plotar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ACF measures the linear relationship between a time series and its lagged values. It calculates the correlation coefficient between the series and its lagged values at different time lags. \n",
    "\n",
    "The ACF plot can provide answers to the following questions:\n",
    "\n",
    "1. Is the observed time series white noise/random?\n",
    "2. Is an observation related to an adjacent observation, an observation twice-removed, and so on?\n",
    "3. Can the observed time series be modeled with an MA model? If yes, what is the order?\n",
    "\n",
    "Source: https://www.kaggle.com/code/iamleonie/time-series-interpreting-acf-and-pacf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, the PACF measures the correlation between a time series and its lagged values while removing the effects of intermediate lags. It represents the correlation between two variables after removing the influence of other variables in between. By analyzing the PACF plot, you can identify the direct influence of each lag on the current value of the time series, independent of the other lags.\n",
    "\n",
    "The PACF plot can provide answers to the following question:\n",
    "\n",
    "1. Can the observed time series be modeled with an AR model? If yes, what is the order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Unique_Code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1['Unique_Code'] == 'M01_OP06_Aug_2019_5']['X_axis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stationarity(series):\n",
    "    # Copied from https://machinelearningmastery.com/time-series-data-stationary-python/\n",
    "\n",
    "    result = adfuller(series.values)\n",
    "\n",
    "    print('ADF Statistic: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "    if (result[1] <= 0.05) & (result[4]['5%'] > result[0]):\n",
    "        print(\"\\u001b[32mStationary\\u001b[0m\")\n",
    "    else:\n",
    "        print(\"\\x1b[31mNon-stationary\\x1b[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_stationarity(df1[df1['Unique_Code'] == 'M01_OP06_Feb_2019_1']['X_axis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20, 6))\n",
    "ax=ax.ravel()\n",
    "\n",
    "# Plot ACF\n",
    "plot_acf(df1[df1['Unique_Code'] == 'M01_OP06_Feb_2019_1']['X_axis'], ax=ax[0], lags=500)\n",
    "ax[0].set_xlabel('Lags')\n",
    "ax[0].set_ylabel('ACF')\n",
    "ax[0].set_title('Autocorrelation Function (ACF)')\n",
    "ax[0].set_xlim([0,100])\n",
    "\n",
    "# Plot PACF\n",
    "plot_pacf(df1[df1['Unique_Code'] == 'M01_OP06_Feb_2019_1']['X_axis'], ax=ax[1], lags=500)\n",
    "ax[1].set_xlabel('Lags')\n",
    "ax[1].set_ylabel('PACF')\n",
    "ax[1].set_title('Partial Autocorrelation Function (PACF)')\n",
    "ax[1].set_xlim([0,40])\n",
    "\n",
    "plt.suptitle('M01_OP06_Feb_2019_1')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20, 6))\n",
    "ax=ax.ravel()\n",
    "\n",
    "# Plot ACF\n",
    "plot_acf(df1[df1['Unique_Code'] == 'M01_OP06_Aug_2021_3']['X_axis'], ax=ax[0], lags=500)\n",
    "ax[0].set_xlabel('Lags')\n",
    "ax[0].set_ylabel('ACF')\n",
    "ax[0].set_title('Autocorrelation Function (ACF)')\n",
    "ax[0].set_xlim([0,100])\n",
    "\n",
    "# Plot PACF\n",
    "plot_pacf(df1[df1['Unique_Code'] == 'M01_OP06_Aug_2021_3']['X_axis'], ax=ax[1], lags=500)\n",
    "ax[1].set_xlabel('Lags')\n",
    "ax[1].set_ylabel('PACF')\n",
    "ax[1].set_title('Partial Autocorrelation Function (PACF)')\n",
    "ax[1].set_xlim([0,40])\n",
    "\n",
    "plt.suptitle('M01_OP06_Aug_2021_3')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20, 6))\n",
    "ax=ax.ravel()\n",
    "\n",
    "# Plot ACF\n",
    "plot_acf(df1[df1['Unique_Code'] == 'M01_OP06_Aug_2019_5']['X_axis'], ax=ax[0], lags=500)\n",
    "ax[0].set_xlabel('Lags')\n",
    "ax[0].set_ylabel('ACF')\n",
    "ax[0].set_title('Autocorrelation Function (ACF)')\n",
    "ax[0].set_xlim([0,100])\n",
    "\n",
    "# Plot PACF\n",
    "plot_pacf(df1[df1['Unique_Code'] == 'M01_OP06_Aug_2019_5']['X_axis'], ax=ax[1], lags=500)\n",
    "ax[1].set_xlabel('Lags')\n",
    "ax[1].set_ylabel('PACF')\n",
    "ax[1].set_title('Partial Autocorrelation Function (PACF)')\n",
    "ax[1].set_xlim([0,40])\n",
    "\n",
    "plt.suptitle('M01_OP06_Aug_2019_5')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A time series is composed by systematic and unsystematic components.\n",
    "\n",
    "- Systematic: Components of the time series that have consistency or recurrence and can be described and modeled.\n",
    "- Non-Systematic: Components of the time series that cannot be directly modeled.\n",
    "\n",
    "A given time series is thought to consist of three systematic components including level, trend, seasonality, and one non-systematic component called noise. These components are defined as follows:\n",
    "\n",
    "- Level: The average value in the series.\n",
    "- Trend: The increasing or decreasing value in the series.\n",
    "- Seasonality: The repeating short-term cycle in the series.\n",
    "- Noise: The random variation in the series.\n",
    "\n",
    "Reference: https://machinelearningmastery.com/decompose-time-series-data-trend-seasonality/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Definir o número de amostras por ciclo\n",
    "samples_per_cycle = 90 * 2000  # 90 segundos * 2000 amostras/segundo\n",
    "\n",
    "# Calcular a tendência usando média móvel com janela de 2000 pontos (1 segundo)\n",
    "df1['trend'] = df1['X_axis'].rolling(window=2000, center=True).mean()\n",
    "df1['trend'].fillna(method='bfill', inplace=True)  # Preenche NaN no início do DataFrame\n",
    "df1['trend'].fillna(method='ffill', inplace=True)  # Preenche NaN no final do DataFrame\n",
    "\n",
    "# Detrend a série\n",
    "df1['detrended'] = df1['X_axis'] - df1['trend']\n",
    "\n",
    "# Calcular a componente sazonal, assumindo que cada ciclo é aproximadamente de 90 segundos\n",
    "# Identificar o ciclo baseado no índice\n",
    "df1['cycle'] = df1.index // samples_per_cycle\n",
    "df1['seasonality'] = df1.groupby('cycle')['detrended'].transform('mean')\n",
    "\n",
    "# Calcular os resíduos\n",
    "df1['resid'] = df1['detrended'] - df1['seasonality']\n",
    "\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "axes[0].plot(df1['X_axis'], label='Original')\n",
    "axes[0].set_title('Original Data')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(df1['trend'], label='Trend', color='orange')\n",
    "axes[1].set_title('Trend')\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(df1['seasonality'], label='Seasonality', color='green')\n",
    "axes[2].set_title('Seasonality')\n",
    "axes[2].legend()\n",
    "\n",
    "axes[3].plot(df1['resid'], label='Residuals', color='red')\n",
    "axes[3].set_title('Residuals')\n",
    "axes[3].legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation(df, machine, process, unique_code=None):\n",
    "    \"\"\"\n",
    "    Plota a matriz de correlação dos eixos X, Y e Z para uma máquina e processo específicos,\n",
    "    com a opção de filtrar por um código único e sem exibir o triângulo superior da matriz.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - df (pandas.DataFrame): DataFrame que contém os dados.\n",
    "    - machine (str): A máquina a ser filtrada.\n",
    "    - process (str): O processo a ser filtrado.\n",
    "    - unique_code (str, opcional): O código único a ser filtrado. Se None, considera todos os códigos.\n",
    "    \"\"\"\n",
    "    # Filtrar por Machine, Process, e opcionalmente por Unique_Code\n",
    "    if unique_code:\n",
    "        filtered_df = df[(df['Machine'] == machine) & (df['Process'] == process) & (df['Unique_Code'] == unique_code)]\n",
    "    else:\n",
    "        filtered_df = df[(df['Machine'] == machine) & (df['Process'] == process)]\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(\"Não foram encontrados dados para os filtros fornecidos.\")\n",
    "        return\n",
    "    \n",
    "    # Calcular a matriz de correlação\n",
    "    correlation_matrix = filtered_df[['X_axis', 'Y_axis', 'Z_axis']].corr()\n",
    "\n",
    "    # Criar a máscara para ocultar o triângulo superior\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool), k=1)\n",
    "\n",
    "    # Plotar o heatmap com a máscara\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', fmt=\".2f\", cbar_kws={'shrink': .8})\n",
    "    plt.title(f'Machine: {machine}, Process: {process}' + (f',\\n Unique_Code: {unique_code}' if unique_code else ''))\n",
    "    plt.grid(True, which='both', color='grey', linestyle='-', linewidth=0.5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation(df, machine = 'M01', process = 'OP06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation(df, machine = 'M01', process = 'OP06', unique_code= 'M01_OP06_Aug_2019_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation(df, machine = 'M01', process = 'OP06', unique_code= 'M01_OP06_Aug_2019_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between sensors is very low and apparently increases only during operations with anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mainfold learning to visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(df['Machine']=='M01') & (df['Process']=='OP06')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Label'] = df1['Label'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df1[::100], x='Z_axis', y='Y_axis', color='Label',\n",
    "                 labels={\n",
    "                     'Z_axis': 'Z Axis',\n",
    "                     'Y_axis': 'Y Axis',\n",
    "                     'Label': 'Label'\n",
    "                 },\n",
    "                 title='Z and Y axis for M01 - OP06')\n",
    "\n",
    "fig.update_layout(width=800, height=600)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df1[::100], x='Z_axis', y='X_axis', color='Label',\n",
    "                 labels={\n",
    "                     'Z_axis': 'Z Axis',\n",
    "                     'Y_axis': 'X Axis',\n",
    "                     'Label': 'Label'\n",
    "                 },\n",
    "                 title='Z and X axis for M01 - OP06')\n",
    "\n",
    "fig.update_layout(width=800, height=600)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df1[::100], x='Y_axis', y='X_axis', color='Label',\n",
    "                 labels={\n",
    "                     'Z_axis': 'Y Axis',\n",
    "                     'Y_axis': 'X Axis',\n",
    "                     'Label': 'Label'\n",
    "                 },\n",
    "                 title='Y and X axis for M01 - OP06')\n",
    "\n",
    "fig.update_layout(width=800, height=600)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_main_df = df1.sample(frac=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(sample_main_df, x='X_axis', y='Y_axis', z='Z_axis',\n",
    "              color='Label')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['X_axis','Y_axis','Z_axis']\n",
    "X = sample_main_df[features]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = pd.DataFrame(X_scaled, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2) \n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "explained_var = pca.explained_variance_ratio_\n",
    "print(\"Explained variance for each component:\", explained_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(data = X_pca[:, :2], columns = ['PC1', 'PC2'])\n",
    "pca_df['Label'] = df1['Label'].values \n",
    "\n",
    "pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(pca_df[::100], x='PC1', y='PC2', color='Label',\n",
    "                 labels={\n",
    "                     'PC1': 'PC1',\n",
    "                     'PC2': 'PC1'\n",
    "                 },\n",
    "                 title='PCA')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "tsne_results = tsne.fit_transform(X_scaled)\n",
    "\n",
    "# Criando um novo DataFrame para os resultados do t-SNE\n",
    "df_tsne = pd.DataFrame(data=tsne_results, columns=['TSNE1', 'TSNE2'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
